{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba830803",
   "metadata": {},
   "source": [
    "# Introduction of camera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cecfa778",
   "metadata": {},
   "source": [
    "![title](images/intro0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b6ed84",
   "metadata": {},
   "source": [
    "![title](images/Intrinsic.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a83da33",
   "metadata": {},
   "source": [
    "![title](images/Extrinsic1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0f8f421",
   "metadata": {},
   "source": [
    "![title](images/distortion.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2649b48",
   "metadata": {},
   "source": [
    "# How to convert 2d information to 3d?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db107f6",
   "metadata": {},
   "source": [
    "![title](images/triangulation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a1d64f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80131736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "80333c68",
   "metadata": {},
   "source": [
    "## 1. Manually organize the collected video files (prototype version) (specific format as shown below, files must be placed exactly as indicated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb77e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def int_to_char(n):\n",
    "    if 0 <= n <= 25:\n",
    "        return chr(ord('A') + n)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be between 0 and 25\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb56f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998df38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'Data/4cams'\n",
    "project_names = ['xyz','xyz_static','intrinsic4cam','mice','checker7mm'] #,''\n",
    "number_camera = 4\n",
    "\n",
    "cam_names = []\n",
    "for i in range(number_camera):\n",
    "    cam_names.append('cam'+int_to_char(i))\n",
    "for p in project_names:\n",
    "    for c in cam_names:\n",
    "        each_path = os.path.join(root_path,os.path.join(p,c))\n",
    "        if not os.path.exists(each_path):\n",
    "            os.makedirs(each_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7aac0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ac89e5d",
   "metadata": {},
   "source": [
    "## 1.5. Synchronize the video files and manually place them in the designated locations (prototype version)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from utils.Sync_prototype import synchronize_videos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda56097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "synchronize_videos(root_path, project_names,cam_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2d793",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eab7bd36",
   "metadata": {},
   "source": [
    "## 2 create the XYZ object we use"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b8d220",
   "metadata": {},
   "source": [
    "![title](images/target.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beb903bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading DLC 2.3.9...\n"
     ]
    }
   ],
   "source": [
    "from utils.Extrinsic_check import XYZ_object\n",
    "xyz = XYZ_object(scaling = 1) #set it to 1 if it is about 6cm object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "962d492f",
   "metadata": {},
   "source": [
    "## 3. Train a DeepLabCut model using transfer learning to detect known 3D objects, and manually place them in the corresponding Anipose positions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12502513",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/murphylab/anaconda3/envs/anipose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/murphylab/anaconda3/envs/anipose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/murphylab/anaconda3/envs/anipose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/murphylab/anaconda3/envs/anipose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/murphylab/anaconda3/envs/anipose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/murphylab/anaconda3/envs/anipose/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm\n",
    "from utils.Extrinsic_check import Generate_refined_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1f63fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bf2088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_config_path = os.path.join(os.getcwd(),'DeepLabCut/pretrained_xyz_model/config.yaml')\n",
    "pretrained_model_appendix = 'DLC_dlcrnetms5_XYZ_resnet50Aug1shuffle1_900000'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75dd933d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 161319.38it/s]\n",
      "100%|█████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 197379.01it/s]\n"
     ]
    }
   ],
   "source": [
    "object_video_path_list = []\n",
    "for project_name in ['xyz','xyz_static',]:\n",
    "    object_video_folder = os.path.join(os.getcwd(), os.path.join('Data',f'4cams/{project_name}'))\n",
    "    \n",
    "    object_video_name_list = [f'{project_name}-camA', \n",
    "                              f'{project_name}-camB', \n",
    "                              f'{project_name}-camC', \n",
    "                              f'{project_name}-camD',]\n",
    "    video_appendix         = '.mp4'\n",
    "    \n",
    "    \n",
    "    for video_name in tqdm.tqdm(object_video_name_list):\n",
    "        video_path = os.path.join(object_video_folder, video_name + video_appendix)\n",
    "        object_video_path_list.append(video_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c9d024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76850fbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.analyze_videos(pretrained_config_path, \n",
    "                          object_video_path_list, \n",
    "                          save_as_csv=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a31d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a416f9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the intrinsic parameters if you have one\n",
    "# Load intrinsic calibration result\n",
    "try:\n",
    "    intrinsic_result = np.load(os.path.join(os.path.join(os.getcwd(),'Data/4cams/intrinsic4cam',),\n",
    "                                            'intrinsic_params.npy'),allow_pickle=True).item()\n",
    "except:\n",
    "    intrinsic_result = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74692d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ec5eed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa349db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dlc_iter1_project_path = os.path.join(os.getcwd(),'DeepLabCut/XYZ-fintune_iter1')\n",
    "dlc_iter2_project_path = os.path.join(os.getcwd(),'DeepLabCut/XYZ-fintune_iter2')\n",
    "dlc_iter3_project_path = os.path.join(os.getcwd(),'DeepLabCut/XYZ-fintune_iter3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc08191a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/4cams/xyz/xyz-camA.mp4',\n",
       " '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/4cams/xyz/xyz-camB.mp4',\n",
       " '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/4cams/xyz/xyz-camC.mp4',\n",
       " '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/4cams/xyz/xyz-camD.mp4',\n",
       " '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/4cams/xyz_static/xyz_static-camA.mp4',\n",
       " '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/4cams/xyz_static/xyz_static-camB.mp4',\n",
       " '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/4cams/xyz_static/xyz_static-camC.mp4',\n",
       " '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/4cams/xyz_static/xyz_static-camD.mp4']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object_video_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "afaa4c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|██████████████████████▉                                      | 3/8 [00:04<00:07,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: do not have enough frames meet criteria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|█████████████████████████████████████████████▊               | 6/8 [00:09<00:02,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: do not have enough frames meet criteria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|█████████████████████████████████████████████████████▍       | 7/8 [00:10<00:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed: do not have enough frames meet criteria\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 8/8 [00:11<00:00,  1.44s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for video_path in tqdm.tqdm(object_video_path_list):\n",
    "    prediction_path = os.path.join(video_path[:-4]+pretrained_model_appendix+'.h5' )\n",
    "    if intrinsic_result is not None:\n",
    "        cam_count   = video_name.split('-')[-1]\n",
    "        instrinsicM = intrinsic_result[cam_count]['intr']\n",
    "        dist        = intrinsic_result[cam_count]['dist']\n",
    "    else:\n",
    "        instrinsicM = None\n",
    "        dist        = None\n",
    "    Generate_refined_training_data(prediction_path, video_path, \n",
    "                                   dlc_iter1_project_path,\n",
    "                                   xyz = xyz, obj_scale = 1, obj_unit = 'mm', \n",
    "                                   instrinsicM = instrinsicM, dist     = dist,\n",
    "                                   min_num_kp_fitting = 6,\n",
    "                                   error_threshold    = 5,\n",
    "                                   skip_frames = 10,\n",
    "                                   conf_thres = .4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f4287",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.add_new_videos(os.path.join(dlc_iter1_project_path,'config.yaml'),\n",
    "                          object_video_path_list, copy_videos=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e5ab11",
   "metadata": {},
   "source": [
    "### Now, it is time to go to deeplabcut GUI for easier life"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6645f1",
   "metadata": {},
   "source": [
    "![title](images/dlc0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2df546",
   "metadata": {},
   "source": [
    "![title](images/dlc1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4a19a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "90e441bf",
   "metadata": {},
   "source": [
    "### For more iterations, repeat previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827ed1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for video_name in tqdm.tqdm(object_video_name_list):\n",
    "    video_path = os.path.join(object_video_folder_iter1, video_name + video_appendix)\n",
    "    prediction_path = os.path.join(object_video_folder , video_name+pretrained_model_appendix+'.h5' )\n",
    "    if intrinsic_result is not None:\n",
    "        cam_count   = video_name.split('-')[-1]\n",
    "        instrinsicM = intrinsic_result[cam_count]['intr']\n",
    "        dist        = intrinsic_result[cam_count]['dist']\n",
    "    else:\n",
    "        instrinsicM = None\n",
    "        dist        = None\n",
    "    Generate_refined_training_data(prediction_path, video_path, \n",
    "                                   dlc_iter2_project_path,\n",
    "                                   xyz = xyz, obj_scale = 1, obj_unit = 'mm', \n",
    "                                   instrinsicM = instrinsicM, dist     = dist,\n",
    "                                   min_num_kp_fitting = 6,\n",
    "                                   error_threshold    = 5,\n",
    "                                   skip_frames = 10,\n",
    "                                   conf_thres = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50ae43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.add_new_videos(os.path.join(dlc_iter2_project_path,'config.yaml'),\n",
    "                          object_video_path_list, copy_videos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739f0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1927674f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f62eac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9157ed4a",
   "metadata": {},
   "source": [
    "## 4. Use Anipose for camera calibration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c00bd7",
   "metadata": {},
   "source": [
    "![title](images/checkerdescription.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f78973e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "In your terminal,\n",
    "conda activate anipose\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe089934",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose calibrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976110d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad4f436b",
   "metadata": {},
   "source": [
    "## 5. Use Anipose for 3D keypoint estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae481296",
   "metadata": {},
   "outputs": [],
   "source": [
    "anipose triangulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3ae0fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80945b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6bfd252",
   "metadata": {},
   "source": [
    "## 6. Check the results of Anipose. If the conditions are met, proceed (good to go). The conditions depend on the actual experiment. If not, go to step 7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d7d03b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Extrinsic_check import XYZ_object, compute_centroid,kabsch_algorithm,\\\n",
    "calculate_3d_error, threshold_confidence,initialize_intr,crop_keypoints\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from utils.Intrinsic_check import iter_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "daf7bb88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/team/TM_Lab/HHao/CSHL/anipose_experiment/anipose_cylinder_bad_init/videos/pose-3d/gray.csv\n",
      "Project: anipose_cylinder_bad_init Trail: gray.csv\n",
      "median error: 14.854 mm\n",
      "mean error  : 18.5994 mm\n",
      "max error   : 2067.9055 mm\n",
      "min error   : 0.5926 mm\n",
      "------------------------------------------\n",
      "/mnt/team/TM_Lab/HHao/CSHL/anipose_experiment/anipose_cylinder_bad_init/videos/pose-3d/gray_cylinder.csv\n",
      "Project: anipose_cylinder_bad_init Trail: gray_cylinder.csv\n",
      "median error: 13.3269 mm\n",
      "mean error  : 15.037 mm\n",
      "max error   : 1055.6076 mm\n",
      "min error   : 1.4825 mm\n",
      "------------------------------------------\n",
      "/mnt/team/TM_Lab/HHao/CSHL/anipose_experiment/anipose_cylinder_bad_init/videos/pose-3d/gray_static.csv\n",
      "Project: anipose_cylinder_bad_init Trail: gray_static.csv\n",
      "median error: 13.3564 mm\n",
      "mean error  : 16.426 mm\n",
      "max error   : 2739.3121 mm\n",
      "min error   : 1.8902 mm\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# read anipose prediction\n",
    "\n",
    "anipose_base_path = os.path.join(os.getcwd()[:-5],'anipose_experiment/')\n",
    "for anipose_p in ['anipose_cylinder_bad_init']: #\n",
    "    for file_p in ['gray.csv','gray_cylinder.csv','gray_static.csv']:\n",
    "        anipose_prediction_path = anipose_base_path+ anipose_p  +'/videos/pose-3d/' + file_p\n",
    "        print(anipose_prediction_path)\n",
    "        try:\n",
    "            prediction = pd.read_csv(anipose_prediction_path)\n",
    "            N_frames = len(prediction)\n",
    "            prediction3d = np.zeros((N_frames,xyz().shape[0],xyz().shape[1]))\n",
    "            for i,j in enumerate(xyz.bodyparts):\n",
    "                prediction3d[:,i,0] =  prediction[f'{j}_x'].values\n",
    "                prediction3d[:,i,1] =  prediction[f'{j}_y'].values\n",
    "                prediction3d[:,i,2] =  prediction[f'{j}_z'].values\n",
    "            error_all = []\n",
    "            for i in range(N_frames):\n",
    "                error_each = calculate_3d_error(xyz(), prediction3d[i])\n",
    "                #print(f\"Mean error: {mean_error}\")\n",
    "                error_all.append(error_each )\n",
    "            error_all = np.array(error_all)\n",
    "            print('Project:',anipose_p, 'Trail:',file_p)\n",
    "            print('median error:',np.round(np.median(error_all),4),'mm')\n",
    "            print('mean error  :'  ,np.round(np.mean(error_all),4)  ,'mm')\n",
    "            print('max error   :'   ,np.round(np.max(error_all) ,4)  ,'mm')\n",
    "            print('min error   :'   ,np.round(np.min(error_all) ,4)  ,'mm')\n",
    "            print('------------------------------------------')\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d691b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2c1fe73",
   "metadata": {},
   "source": [
    "## 7. Perform intrinsic calibration and check the error.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad88461",
   "metadata": {},
   "source": [
    "![title](images/checkerdescription.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b013095",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Intrinsic_check import CheckerBoard\n",
    "# Define Checkerboard\n",
    "checkerboard = CheckerBoard(12,9,7) # defined as calib.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de308979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2c3cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Intrinsic_check import create_dataset_for_calibration\n",
    "p  = 'intrinsic4cam'\n",
    "for i in range(number_camera):\n",
    "    YOUR_VIDEO_PATH    = os.path.join(root_path,p)\n",
    "    YOUR_VIDEO_NAME    =  f'{p}-{cam_names[i]}.mp4'\n",
    "    create_dataset_for_calibration(YOUR_VIDEO_PATH, YOUR_VIDEO_NAME ,checkerboard, \n",
    "                                   sample_ratio = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29861e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Intrinsic_check import kmean_pick_dataset\n",
    "for i in range(number_camera):\n",
    "    YOUR_VIDEO_PATH    = os.path.join(root_path,p)\n",
    "    YOUR_VIDEO_NAME    =  f'{p}-{cam_names[i]}.mp4'\n",
    "    checker_img_folder = os.path.join(YOUR_VIDEO_PATH,f'{YOUR_VIDEO_NAME[:-4]}_checker_img')\n",
    "    # we choose a total of 128 images from the folder\n",
    "    kmean_pick_dataset(checker_img_folder,numframes2pick = 128) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367dc42d",
   "metadata": {},
   "source": [
    "### Delete the outliers in the folder YOUR_VIDEO_PATH/YOUR_VIDEO_NAME_checker_img/overlay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e9ca01",
   "metadata": {},
   "source": [
    "![title](images/badchecker2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a72b89d",
   "metadata": {},
   "source": [
    "![title](images/badchecker3.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea6cd9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### it split the checker images into two parts, training and validation.\n",
    "from utils.Intrinsic_check import split_train_test\n",
    "for i in range(number_camera):\n",
    "    YOUR_VIDEO_PATH    = os.path.join(root_path,p)\n",
    "    YOUR_VIDEO_NAME    =  f'{p}-{cam_names[i]}.mp4'\n",
    "    checker_img_folder = os.path.join(YOUR_VIDEO_PATH,f'{YOUR_VIDEO_NAME[:-4]}_checker_img')\n",
    "    split_train_test(checker_img_folder, train_test_ratio = 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46df9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Intrinsic_check import calibrate_kmean_pick_frames\n",
    "from utils.Intrinsic_check import validate_calibrate\n",
    "# load imgpoints generate during creating datasets\n",
    "\n",
    "\n",
    "result = {}\n",
    "for i in range(number_camera):\n",
    "    YOUR_VIDEO_PATH    = os.path.join(root_path,p)\n",
    "    YOUR_VIDEO_NAME    =  f'{p}-{cam_names[i]}.mp4'\n",
    "    checker_img_folder = os.path.join(YOUR_VIDEO_PATH,f'{YOUR_VIDEO_NAME[:-4]}_checker_img')\n",
    "    ret,instrinsicM,dist = calibrate_kmean_pick_frames(checker_img_folder,checkerboard,numframes2pick = 64) \n",
    "    result[cam_names[i]] = {}\n",
    "    result[cam_names[i]]['error'] = ret\n",
    "    result[cam_names[i]]['intr']  = instrinsicM\n",
    "    result[cam_names[i]]['dist']  = dist\n",
    "    \n",
    "    print('training reprojection error',ret,'pixels','\\n',\n",
    "          'intrinsic matrix:','\\n',instrinsicM,'\\n',\n",
    "          'distortion','\\n',np.round(dist,5))\n",
    "    vali_error = validate_calibrate(checker_img_folder,checkerboard,instrinsicM,dist)\n",
    "    print('validation error:', vali_error,'pixels')\n",
    "    result[cam_names[i]]['val_error'] = vali_error\n",
    "    print('-------------')\n",
    "np.save(os.path.join(os.path.join(root_path,p),'intrinsic_params'),result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34291fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fafc3736",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bde306c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ca3fb94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da6dc17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51a8d1a8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7188bc14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ee0822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc36f1a",
   "metadata": {},
   "source": [
    "## 8. Refine the object detection results and retain the accurate detection points.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5568ad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Extrinsic_check import refine_dlc_prediction\n",
    "from utils.Extrinsic_check import Generate_refined_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af005bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction_path = '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/anipose_experiment/anipose_cylinder_refined/videos/pose-2d/gray_cylinder-camF.h5'\n",
    "#video_path      =  '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/anipose_experiment/anipose_cylinder_refined/videos/gray_cylinder-camF.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892a077b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec5e75a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_paths      =  ['/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/DeepLabCut/XYZ-fintune_iter2/videos/xyz_static-camD.mp4',\n",
    "                     '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/DeepLabCut/XYZ-fintune_iter2/videos/xyz_static-camC.mp4',\n",
    "                     '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/DeepLabCut/XYZ-fintune_iter2/videos/xyz_static-camB.mp4',\n",
    "                     '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/DeepLabCut/XYZ-fintune_iter2/videos/xyz_static-camA.mp4',\n",
    "                     '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/DeepLabCut/XYZ-fintune_iter2/videos/xyz-camD.mp4',\n",
    "                     '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/DeepLabCut/XYZ-fintune_iter2/videos/xyz-camC.mp4',\n",
    "                     '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/DeepLabCut/XYZ-fintune_iter2/videos/xyz-camB.mp4',\n",
    "                    '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/DeepLabCut/XYZ-fintune_iter2/videos/xyz-camA.mp4',]\n",
    "DLC_appdix = 'DLC_resnet50_XYZ_resnet50Aug1shuffle1_1100000'\n",
    "for video_path in video_paths:\n",
    "    if intrinsic_result is not None:\n",
    "        cam_count   = video_path.split('-')[-1]\n",
    "        instrinsicM = intrinsic_result[cam_count]['intr']\n",
    "        dist        = intrinsic_result[cam_count]['dist']\n",
    "    else:\n",
    "        instrinsicM = None\n",
    "        dist  = None\n",
    "    prediction_path = video_path[:-4] + DLC_appdix  + '.h5'\n",
    "    refine_dlc_prediction(video_path,                # Path to the video file\n",
    "                          prediction_path,           # Path to the prediction file\n",
    "                          confident_threshold=0.8,   # Threshold for keypoint confidence (default: 0.6) \n",
    "                          xyz_scaling=1,             # Scaling factor for XYZ coordinates (default: 1,refers to original 6cm object)\n",
    "                          instrinsicM=instrinsicM,          # Intrinsic camera matrix (not used here)\n",
    "                          dist       =dist ,          # Distortion coefficients (not used here)\n",
    "                          error_threshold=3,         # Threshold for allowable error (default: 3) \n",
    "                          min_number_kp_opt = 6,     #  Minimum number of keypoints for optimization (default: 6) \n",
    "                          output_appendix   = 'filtered',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d2004ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353c823",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "10c0c659",
   "metadata": {},
   "source": [
    "## 9. Re-estimate the extrinsic parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7754ada",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'toml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrefine_calibration\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m refine_calibration\n",
      "File \u001b[0;32m/mnt/team/TM_Lab/HHao/CSHL/Demos/utils/refine_calibration.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mExtrinsic_check\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m create_ba_dataset\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maniposelib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcameras\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CameraGroup\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manipose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01manipose\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  load_config\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01manipose\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcalibrate\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_2d_data,process_points_for_calibration\n",
      "File \u001b[0;32m/mnt/team/TM_Lab/HHao/CSHL/Demos/utils/aniposelib/__init__.py:6\u001b[0m\n\u001b[1;32m      3\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0.6.1\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m VERSION \u001b[38;5;241m=\u001b[39m __version__\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m boards, cameras, utils\n",
      "File \u001b[0;32m/mnt/team/TM_Lab/HHao/CSHL/Demos/utils/aniposelib/cameras.py:10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumba\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m jit\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m defaultdict, Counter\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtoml\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m trange\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'toml'"
     ]
    }
   ],
   "source": [
    "from utils.refine_calibration import refine_calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23a403d-dec8-41df-9ad0-f1c1baf1f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "anipose_path = '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/anipose_experiment/anipose_cylinder_bad_init'\n",
    "intrinsic_result_path = os.path.join('/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/Data/intrinsic',\n",
    "                                        'intrinsic_params.npy')  \n",
    "video_folder  = '/mnt/TeamShare/TM_Lab/HHao/CSHL/Demos/anipose_experiment/anipose_cylinder_pyba/videos/videos-raw'\n",
    "video_name_list = ['gray_static-camF', 'gray_static-camE','gray_static-camD', \n",
    "                   'gray_static-camC', 'gray_static-camB', 'gray_static-camA',]\n",
    "video_name_list.sort()\n",
    "all_points, all_scores = create_ba_dataset(video_folder,video_name_list)\n",
    "refine_calibration(anipose_path,intrinsic_result_path, all_points, all_scores, file_appendix = '-refine')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c4b87",
   "metadata": {},
   "source": [
    "## 11 .Return to step 6 to check the results of Anipose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec085020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read anipose prediction\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "anipose_base_path = os.path.join(os.getcwd()[:-5],'anipose_experiment/')\n",
    "for anipose_p in ['anipose_cylinder_bad_init_finetune']: #\n",
    "    for file_p in ['gray.csv','gray_cylinder.csv','gray_static.csv']:\n",
    "        anipose_prediction_path = anipose_base_path+ anipose_p  +'/videos/pose-3d/' + file_p\n",
    "        print(anipose_prediction_path)\n",
    "        \n",
    "        prediction = pd.read_csv(anipose_prediction_path)\n",
    "        N_frames = len(prediction)\n",
    "        prediction3d = np.zeros((N_frames,xyz().shape[0],xyz().shape[1]))\n",
    "        for i,j in enumerate(xyz.bodyparts):\n",
    "            prediction3d[:,i,0] =  prediction[f'{j}_x'].values\n",
    "            prediction3d[:,i,1] =  prediction[f'{j}_y'].values\n",
    "            prediction3d[:,i,2] =  prediction[f'{j}_z'].values\n",
    "        error_all = []\n",
    "        for i in range(N_frames):\n",
    "            error_each = calculate_3d_error(xyz(), prediction3d[i])\n",
    "            #print(f\"Mean error: {mean_error}\")\n",
    "            error_all.append(error_each )\n",
    "        error_all = np.array(error_all)\n",
    "        print('Project:',anipose_p, 'Trail:',file_p)\n",
    "        print('median error:',np.round(np.median(error_all),4),'mm')\n",
    "        print('mean error  :'  ,np.round(np.mean(error_all),4)  ,'mm')\n",
    "        print('max error   :'   ,np.round(np.max(error_all) ,4)  ,'mm')\n",
    "        print('min error   :'   ,np.round(np.min(error_all) ,4)  ,'mm')\n",
    "        print('------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d322bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9633a637",
   "metadata": {},
   "source": [
    "# 12. Analysis on 3d keypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23074ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv file\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0195fb-e7dd-40ea-a825-d78ec3be8579",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b76e0646",
   "metadata": {},
   "outputs": [],
   "source": [
    "data3d = pd.read_csv('/mnt/team/TM_Lab/HHao/CSHL/Demos/anipose_demo/mice_2023/videos/pose-3d/DTL2_2023-07-28_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d0a52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb26e932",
   "metadata": {},
   "outputs": [],
   "source": [
    "reducer = umap.UMAP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed01911",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = reducer.fit_transform(data3d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b5387b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07755c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(\n",
    "    embedding[:, 0],\n",
    "    embedding[:, 1],)\n",
    "plt.gca().set_aspect('equal', 'datalim')\n",
    "plt.title('UMAP projection of the Demo dataset', fontsize=24);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b8f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
